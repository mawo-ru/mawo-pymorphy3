"""–ó–∞–≥—Ä—É–∑—á–∏–∫ DAWG —Å–ª–æ–≤–∞—Ä–µ–π –≤ —Ñ–æ—Ä–º–∞—Ç–µ pymorphy2
–ó–∞–≥—Ä—É–∂–∞–µ—Ç —Å–∫–æ–º–ø–∏–ª–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ —Å–ª–æ–≤–∞—Ä–∏ –≤ —Ñ–æ—Ä–º–∞—Ç–µ pymorphy2 —Å DAWG —Å—Ç—Ä—É–∫—Ç—É—Ä–∞–º–∏.
"""

from __future__ import annotations

import json
import logging
import struct
from pathlib import Path
from typing import Any

logger = logging.getLogger(__name__)


class DAWGDictionary:
    """–ó–∞–≥—Ä—É–∂–∞–µ—Ç –∏ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª—è–µ—Ç –¥–æ—Å—Ç—É–ø –∫ DAWG —Å–ª–æ–≤–∞—Ä—è–º pymorphy2."""

    def __init__(self, dict_path: str | Path) -> None:
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∑–∞–≥—Ä—É–∑—á–∏–∫–∞ DAWG —Å–ª–æ–≤–∞—Ä—è.

        Args:
            dict_path: –ü—É—Ç—å –∫ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏ —Å–æ —Å–ª–æ–≤–∞—Ä–Ω—ã–º–∏ —Ñ–∞–π–ª–∞–º–∏ pymorphy2
        """
        self.dict_path = Path(dict_path)
        self.meta: dict[str, Any] = {}
        self.grammemes: list[list[str]] = []
        self.suffixes: list[str] = []
        self.gramtab: list[list[int]] = []
        self.paradigms: list[tuple[int, int]] = []
        self.words_dawg: Any = None
        self.prediction_dawgs: list[Any] = []

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç—å –±–∏–±–ª–∏–æ—Ç–µ–∫–∏ DAWG
        try:
            import dawg  # type: ignore[import-not-found]

            self._dawg_module = dawg
            self._dawg_available = True
        except ImportError:
            logger.error("‚ùå dawg-python –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω. –£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ: pip install dawg-python")
            self._dawg_available = False
            raise ImportError("dawg-python —Ç—Ä–µ–±—É–µ—Ç—Å—è –¥–ª—è –ø–æ–¥–¥–µ—Ä–∂–∫–∏ DAWG —Å–ª–æ–≤–∞—Ä–µ–π") from None

        # –ó–∞–≥—Ä—É–∂–∞–µ–º –≤—Å–µ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã —Å–ª–æ–≤–∞—Ä—è
        self._load_meta()
        self._load_grammemes()
        self._load_suffixes()
        self._load_gramtab()
        self._load_paradigms()
        self._load_words_dawg()
        self._load_prediction_dawgs()

        logger.info(f"‚úÖ DAWG —Å–ª–æ–≤–∞—Ä—å –∑–∞–≥—Ä—É–∂–µ–Ω –∏–∑ {self.dict_path}")
        logger.info(f"   –°–ª–æ–≤: {len(list(self.words_dawg.keys()))} –∑–∞–ø–∏—Å–µ–π")
        logger.info(f"   –ü–∞—Ä–∞–¥–∏–≥–º: {len(self.paradigms)}")
        logger.info(f"   –°—É—Ñ—Ñ–∏–∫—Å–æ–≤: {len(self.suffixes)}")
        logger.info(f"   –ì—Ä–∞–º–º–µ–º: {len(self.gramtab)} —Ç–µ–≥–æ–≤")

    def _load_meta(self) -> None:
        """–ó–∞–≥—Ä—É–∑–∫–∞ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö —Å–ª–æ–≤–∞—Ä—è –∏–∑ meta.json."""
        meta_path = self.dict_path / "meta.json"
        with open(meta_path, encoding="utf-8") as f:
            meta_list = json.load(f)
            self.meta = dict(meta_list)

        logger.info(f"üìã –ó–∞–≥—Ä—É–∂–µ–Ω—ã –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ: —Ñ–æ—Ä–º–∞—Ç {self.meta.get('format_version')}")

    def _load_grammemes(self) -> None:
        """–ó–∞–≥—Ä—É–∑–∫–∞ –≥—Ä–∞–º–º–µ–º –∏–∑ grammemes.json."""
        grammemes_path = self.dict_path / "grammemes.json"
        with open(grammemes_path, encoding="utf-8") as f:
            self.grammemes = json.load(f)

        logger.debug(f"üìö –ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(self.grammemes)} –≥—Ä–∞–º–º–µ–º")

    def _load_suffixes(self) -> None:
        """–ó–∞–≥—Ä—É–∑–∫–∞ —Å—É—Ñ—Ñ–∏–∫—Å–æ–≤ –∏–∑ suffixes.json."""
        suffixes_path = self.dict_path / "suffixes.json"
        with open(suffixes_path, encoding="utf-8") as f:
            self.suffixes = json.load(f)

        logger.debug(f"üìù –ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(self.suffixes)} —Å—É—Ñ—Ñ–∏–∫—Å–æ–≤")

    def _load_gramtab(self) -> None:
        """–ó–∞–≥—Ä—É–∑–∫–∞ –≥—Ä–∞–º–º–∞—Ç–∏—á–µ—Å–∫–æ–π —Ç–∞–±–ª–∏—Ü—ã –∏–∑ gramtab-opencorpora-int.json."""
        gramtab_format = self.meta.get("gramtab_formats", {}).get(
            "opencorpora-int", "gramtab-opencorpora-int.json"
        )
        gramtab_path = self.dict_path / gramtab_format

        with open(gramtab_path, encoding="utf-8") as f:
            self.gramtab = json.load(f)

        logger.debug(f"üè∑Ô∏è  –ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(self.gramtab)} –∑–∞–ø–∏—Å–µ–π gramtab")

    def _load_paradigms(self) -> None:
        """–ó–∞–≥—Ä—É–∑–∫–∞ –ø–∞—Ä–∞–¥–∏–≥–º –∏–∑ –±–∏–Ω–∞—Ä–Ω–æ–≥–æ —Ñ–∞–π–ª–∞ paradigms.array."""
        paradigms_path = self.dict_path / "paradigms.array"

        with open(paradigms_path, "rb") as f:
            paradigms_data = f.read()

        # –ö–∞–∂–¥–∞—è —Ñ–æ—Ä–º–∞ - 2 unsigned shorts (little-endian): (suffix_id, gramtab_id)
        paradigm_format = "<HH"  # little-endian!
        paradigm_size = struct.calcsize(paradigm_format)
        paradigms_count = len(paradigms_data) // paradigm_size

        self.paradigms = []
        for i in range(paradigms_count):
            offset = i * paradigm_size
            suffix_id, gramtab_id = struct.unpack(
                paradigm_format, paradigms_data[offset : offset + paradigm_size]
            )
            self.paradigms.append((suffix_id, gramtab_id))

        logger.debug(f"üì¶ –ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(self.paradigms)} —Å–ª–æ–≤–æ—Ñ–æ—Ä–º –≤ –ø–∞—Ä–∞–¥–∏–≥–º–∞—Ö")

    def _load_words_dawg(self) -> None:
        """–ó–∞–≥—Ä—É–∑–∫–∞ —Å–ª–æ–≤ –∏–∑ words.dawg."""
        words_path = self.dict_path / "words.dawg"

        # RecordDAWG —Å —Ñ–æ—Ä–º–∞—Ç–æ–º >HH (paradigm_id, word_idx)
        self.words_dawg = self._dawg_module.RecordDAWG(">HH")
        self.words_dawg = self.words_dawg.load(str(words_path))

        logger.debug(f"üìñ –ó–∞–≥—Ä—É–∂–µ–Ω DAWG —Å–ª–æ–≤ –∏–∑ {words_path.name}")

    def _load_prediction_dawgs(self) -> None:
        """–ó–∞–≥—Ä—É–∑–∫–∞ DAWG —Å–ª–æ–≤–∞—Ä–µ–π –¥–ª—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è."""
        prefix_count = len(self.meta.get("compile_options", {}).get("paradigm_prefixes", [""]))

        self.prediction_dawgs = []
        for prefix_id in range(prefix_count):
            prediction_path = self.dict_path / f"prediction-suffixes-{prefix_id}.dawg"

            if prediction_path.exists():
                # PredictionSuffixesDAWG –∏—Å–ø–æ–ª—å–∑—É–µ—Ç —Ç–æ—Ç –∂–µ —Ñ–æ—Ä–º–∞—Ç
                pred_dawg = self._dawg_module.RecordDAWG(">HH")
                pred_dawg = pred_dawg.load(str(prediction_path))
                self.prediction_dawgs.append(pred_dawg)
            else:
                logger.warning(f"‚ö†Ô∏è  Prediction DAWG –Ω–µ –Ω–∞–π–¥–µ–Ω: {prediction_path.name}")

        logger.debug(f"üîÆ –ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(self.prediction_dawgs)} prediction DAWGs")

    def get_word_parses(self, word: str) -> list[tuple[int, int]]:
        """–ü–æ–ª—É—á–∏—Ç—å —Ä–∞–∑–±–æ—Ä—ã —Å–ª–æ–≤–∞ –∏–∑ DAWG.

        Args:
            word: –°–ª–æ–≤–æ –¥–ª—è –ø–æ–∏—Å–∫–∞

        Returns:
            –°–ø–∏—Å–æ–∫ –∫–æ—Ä—Ç–µ–∂–µ–π (paradigm_id, word_idx)
        """
        if word not in self.words_dawg:
            return []

        return self.words_dawg[word]

    def get_paradigm(self, paradigm_id: int, word_idx: int) -> tuple[str, str] | None:
        """–ü–æ–ª—É—á–∏—Ç—å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –ø–∞—Ä–∞–¥–∏–≥–º–µ.

        Args:
            paradigm_id: ID –ø–∞—Ä–∞–¥–∏–≥–º—ã
            word_idx: –ò–Ω–¥–µ–∫—Å —Å–ª–æ–≤–æ—Ñ–æ—Ä–º—ã –≤ –ø–∞—Ä–∞–¥–∏–≥–º–µ

        Returns:
            –ö–æ—Ä—Ç–µ–∂ (suffix, tag_string) –∏–ª–∏ None
            tag_string - —Å—Ç—Ä–æ–∫–∞ –≤–∏–¥–∞ "NOUN,anim,masc sing,nomn"
        """
        # –í pymorphy2 –ø–∞—Ä–∞–¥–∏–≥–º—ã —Ö—Ä–∞–Ω—è—Ç—Å—è –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ –≤ paradigms.array
        # paradigm_id + word_idx –¥–∞–µ—Ç –ø–æ–∑–∏—Ü–∏—é –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–π —Å–ª–æ–≤–æ—Ñ–æ—Ä–º—ã
        form_index = paradigm_id + word_idx

        if form_index >= len(self.paradigms):
            return None

        suffix_id, gramtab_id = self.paradigms[form_index]

        if suffix_id >= len(self.suffixes):
            return None

        suffix = self.suffixes[suffix_id]

        if gramtab_id >= len(self.gramtab):
            return None

        tag_string = self.gramtab[gramtab_id]

        return (suffix, tag_string)

    def parse_tag_string(self, tag_string: str) -> tuple[str, set[str]]:
        """–†–∞–∑–æ–±—Ä–∞—Ç—å —Å—Ç—Ä–æ–∫—É —Ç–µ–≥–∞ –Ω–∞ POS –∏ –≥—Ä–∞–º–º–µ–º—ã.

        Args:
            tag_string: –°—Ç—Ä–æ–∫–∞ –≤–∏–¥–∞ "NOUN,anim,masc sing,nomn"

        Returns:
            –ö–æ—Ä—Ç–µ–∂ (POS, set(grammemes))
            –ù–∞–ø—Ä–∏–º–µ—Ä: ("NOUN", {"anim", "masc", "sing", "nomn"})
        """
        parts = tag_string.replace(" ", ",").split(",")
        if not parts:
            return ("UNKN", set())

        pos = parts[0]
        grammemes = set(parts[1:]) if len(parts) > 1 else set()

        return (pos, grammemes)

    def word_is_known(self, word: str) -> bool:
        """–ü—Ä–æ–≤–µ—Ä–∏—Ç—å –Ω–∞–ª–∏—á–∏–µ —Å–ª–æ–≤–∞ –≤ —Å–ª–æ–≤–∞—Ä–µ.

        Args:
            word: –°–ª–æ–≤–æ –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏

        Returns:
            True –µ—Å–ª–∏ —Å–ª–æ–≤–æ –∏–∑–≤–µ—Å—Ç–Ω–æ
        """
        return word in self.words_dawg


__all__ = ["DAWGDictionary"]
